{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/home/acct-seeyjc/seeyjc-tyh/.conda/envs/gqs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import qutip\n",
    "import scipy as sp\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading test dataset from N_10_NM_1000_S_20...\n",
      "### Total number of samples: 20\n",
      "### The dimension of conditions: 9\n",
      "### The number of qubits: 10\n",
      "### Data samples...\n",
      " [[1.82 0.98 1.3  0.16 1.87 1.56 1.31 1.68 0.47]\n",
      " [0.36 1.53 0.18 1.6  1.54 0.17 0.41 0.06 0.17]] \n",
      " [[5 3 4 5 0 5 3 0 4 2]\n",
      " [5 2 5 0 1 5 1 0 5 4]]\n",
      "(20, 1000, 10) (20, 9)\n"
     ]
    }
   ],
   "source": [
    "from read_data import load_test_data\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str, default='ppt', choices=['train', 'valid', 'test'], help='dataset split used to decode')\n",
    "parser.add_argument('--data_dir', type=str, default='N_10_NM_1000_S_20', help='path to the folder of diffusion model')\n",
    "parser.add_argument('--seed', type=int, default=101, help='random seed')\n",
    "\n",
    "parser.add_argument('--num_measurements', type=int, default=1000, help='batch size')\n",
    "parser.add_argument('--num_qubits', type=int, default=10, help='batch size')\n",
    "# parser.add_argument('--split', type=str, default='train', choices=['train', 'valid', 'test'], help='dataset split used to decode')\n",
    "# parser.add_argument('--shots', type=int, default=1000, help='number of shots for generation')\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "num_measurements = args.num_measurements\n",
    "num_qubits = args.num_qubits\n",
    "\n",
    "true_data = load_test_data(args, num_measurements=num_measurements)\n",
    "print(true_data[\"input_ids\"].shape, true_data[\"conditions\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20000, 10)\n"
     ]
    }
   ],
   "source": [
    "# samples = pd.read_csv('generation_outputs/results/conditional_heisenberg_N10/model/ns1000/iter50000_lr0.001_wd0_bs512_dropout0.0_lrschedulewarmup_cosine20240518-014155/checkpoints/checkpoint_50000.pth.tar/samples_all.txt'\n",
    "#     , header=None).to_numpy(dtype=int).reshape(-1, 50000, 10)\n",
    "path = './samples/diffuseq_N10_h128_lr0.0001_t2000_sqrt_lossaware_seed102_test-qqp20240923-02:13:49/ema_0.9999_050000.pt.samples/seed123_step0.txt'\n",
    "samples = np.loadtxt(path,  delimiter=',', dtype=int)\n",
    "samples = samples[:, 1:]\n",
    "samples = samples.reshape(20, -1, num_qubits)\n",
    "print(samples.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.82000005, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.82000005, 0.        , 0.98000002, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.98000002, 0.        , 1.29999995, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.29999995, 0.        , 0.16      ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.16      , 0.        ,\n",
       "        1.87      , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.87      ,\n",
       "        0.        , 1.55999994, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.55999994, 0.        , 1.30999994, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.30999994, 0.        , 1.67999995, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.67999995, 0.        , 0.47      ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.47      , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_coupling_matrix(coupling_strength):\n",
    "    rows = 1\n",
    "    cols = len(coupling_strength)+1\n",
    "\n",
    "    qubits = rows * cols\n",
    "    \n",
    "    # Create a 2D Lattice\n",
    "    edges = [\n",
    "        (si, sj) for (si, sj) in it.combinations(range(qubits), 2)\n",
    "        if ((sj % cols > 0) and sj - si == 1) or sj - si == cols\n",
    "    ]\n",
    "    \n",
    "    # sample edge weights uniformly at random from [0, 2]\n",
    "    edge_weights = coupling_strength\n",
    "\n",
    "    coupling_matrix = np.zeros((qubits, qubits))\n",
    "    for (i, j), w in zip(edges, edge_weights):\n",
    "        coupling_matrix[i, j] = coupling_matrix[j, i] = w\n",
    "        \n",
    "    return coupling_matrix\n",
    "\n",
    "# define the system size and lattice geometry\n",
    "rows, cols = 1, num_qubits\n",
    "wires = rows * cols\n",
    "\n",
    "# sample a coupling matrix\n",
    "J_list = [load_coupling_matrix(J) for J in true_data['conditions']]\n",
    "J_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/home/acct-seeyjc/seeyjc-tyh/.conda/envs/gqs/lib/python3.9/site-packages/pennylane/utils.py:67: UserWarning: The method sparse_hamiltonian is deprecated. Please use the method sparse_matrix of the Hamiltonian operator instead.\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [00:00<00:00, 42.01it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_hamiltonian(coupling_matrix):\n",
    "    coeffs, ops = [], []\n",
    "    ns = coupling_matrix.shape[0]\n",
    "\n",
    "    for i, j in it.combinations(range(ns), r=2):\n",
    "        coeff = coupling_matrix[i, j]\n",
    "        if coeff:\n",
    "            for op in [qml.PauliX, qml.PauliY, qml.PauliZ]:\n",
    "                coeffs.append(coeff)\n",
    "                ops.append(op(i) @ op(j))\n",
    "\n",
    "    return qml.Hamiltonian(coeffs, ops)\n",
    "\n",
    "# build sparse hamiltonian\n",
    "H_list = [build_hamiltonian(J) for J in J_list]\n",
    "H_sparse_list = [qml.utils.sparse_hamiltonian(H) for H in H_list]\n",
    "\n",
    "# diagonalize\n",
    "eigvals_list, eigvecs_list = [], []\n",
    "ground_states_list = []\n",
    "for H_sparse in tqdm(H_sparse_list):\n",
    "    eigvals, eigvecs = sp.sparse.linalg.eigs(H_sparse, which='SR', k=1)\n",
    "    eigvals = eigvals.real\n",
    "    ground_state = eigvecs[:, np.argmin(eigvals)]\n",
    "    eigvals_list.append(eigvals)\n",
    "    eigvecs_list.append(eigvecs)\n",
    "    ground_states_list.append(ground_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:12<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# this circuit measures observables for the provided ground state\n",
    "@qml.qnode(device=qml.device('default.qubit', wires=wires, shots=None))\n",
    "def circ(observables):\n",
    "    qml.QubitStateVector(ground_state, wires=range(wires))\n",
    "    return [qml.expval(o) for o in observables]\n",
    "\n",
    "\n",
    "def compute_exact_correlation_matrix(ground_state, wires):\n",
    "    # setup observables for correlation function\n",
    "    def corr_function(i, j):\n",
    "        ops = []\n",
    "        \n",
    "        for op in [qml.PauliX, qml.PauliY, qml.PauliZ]:\n",
    "            if i != j:\n",
    "                ops.append(op(i) @ op(j))\n",
    "            else:\n",
    "                ops.append(qml.Identity(i))\n",
    "\n",
    "        return ops\n",
    "    \n",
    "    # indices for sites for which correlations will be computed\n",
    "    coupling_pairs = list(it.product(range(wires), repeat=2))\n",
    "    \n",
    "    # compute exact correlation matrix\n",
    "    correlation_matrix = np.zeros((wires, wires))\n",
    "    for idx, (i, j) in enumerate(coupling_pairs):\n",
    "        observable = corr_function(i, j)\n",
    "\n",
    "        if i == j:\n",
    "            correlation_matrix[i][j] = 1.0\n",
    "        else:\n",
    "            correlation_matrix[i][j] = (\n",
    "                    np.sum(np.array([circ(observables=[o]) for o in observable]).T) / 3\n",
    "            )\n",
    "            correlation_matrix[j][i] = correlation_matrix[i][j]\n",
    "\n",
    "    return correlation_matrix\n",
    "\n",
    "exact_correlation_matrix_list = [compute_exact_correlation_matrix(ground_state, wires) for ground_state in tqdm(ground_states_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "diag requires an array of at least two dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m             entropies[i, j] \u001b[38;5;241m=\u001b[39m entropies[j, i] \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m entropies\n\u001b[0;32m---> 16\u001b[0m exact_entropy_matrix_list \u001b[38;5;241m=\u001b[39m [compute_exact_entropy_matrix(ground_state, wires) \u001b[38;5;28;01mfor\u001b[39;00m ground_state \u001b[38;5;129;01min\u001b[39;00m tqdm(ground_states_list)]\n",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m             entropies[i, j] \u001b[38;5;241m=\u001b[39m entropies[j, i] \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m entropies\n\u001b[0;32m---> 16\u001b[0m exact_entropy_matrix_list \u001b[38;5;241m=\u001b[39m [\u001b[43mcompute_exact_entropy_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ground_state \u001b[38;5;129;01min\u001b[39;00m tqdm(ground_states_list)]\n",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m, in \u001b[0;36mcompute_exact_entropy_matrix\u001b[0;34m(ground_state, wires)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(wires):\n\u001b[1;32m      7\u001b[0m     ptrace_diag \u001b[38;5;241m=\u001b[39m ground_state_qobj\u001b[38;5;241m.\u001b[39mptrace(sel\u001b[38;5;241m=\u001b[39m[i])\n\u001b[0;32m----> 8\u001b[0m     entropies[i, i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mptrace_diag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mptrace_diag\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreal)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, wires):\n\u001b[1;32m     11\u001b[0m         ptrace \u001b[38;5;241m=\u001b[39m ground_state_qobj\u001b[38;5;241m.\u001b[39mptrace(sel\u001b[38;5;241m=\u001b[39m[i, j])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/gqs/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1748\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(a, offset, axis1, axis2, dtype, out)\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[39mreturn\u001b[39;00m asarray(a)\u001b[39m.\u001b[39mtrace(offset\u001b[39m=\u001b[39moffset, axis1\u001b[39m=\u001b[39maxis1, axis2\u001b[39m=\u001b[39maxis2, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout)\n\u001b[1;32m   1747\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1748\u001b[0m     \u001b[39mreturn\u001b[39;00m asanyarray(a)\u001b[39m.\u001b[39;49mtrace(offset\u001b[39m=\u001b[39;49moffset, axis1\u001b[39m=\u001b[39;49maxis1, axis2\u001b[39m=\u001b[39;49maxis2, dtype\u001b[39m=\u001b[39;49mdtype, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[0;31mValueError\u001b[0m: diag requires an array of at least two dimensions"
     ]
    }
   ],
   "source": [
    "def compute_exact_entropy_matrix(ground_state, wires):\n",
    "    ground_state_qobj = qutip.Qobj(ground_state, dims=[[2] * wires, [1] * wires])\n",
    "\n",
    "    # compute entropies\n",
    "    entropies = np.zeros(shape=(wires, wires), dtype=float)\n",
    "    for i in range(wires):\n",
    "        ptrace_diag = ground_state_qobj.ptrace(sel=[i])\n",
    "        entropies[i, i] = -np.log(np.trace(ptrace_diag * ptrace_diag).real)\n",
    "\n",
    "        for j in range(i + 1, wires):\n",
    "            ptrace = ground_state_qobj.ptrace(sel=[i, j])\n",
    "            e = -np.log(np.trace(ptrace * ptrace).real)\n",
    "            entropies[i, j] = entropies[j, i] = e\n",
    "\n",
    "    return entropies\n",
    "exact_entropy_matrix_list = [compute_exact_entropy_matrix(ground_state, wires) for ground_state in tqdm(ground_states_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit\n",
    "import jax.numpy as jnp\n",
    "\n",
    "@jit\n",
    "def _jax_compute_size_one_entropies(x):\n",
    "    return -jnp.log(jnp.einsum('timl,silm->i', x, x))\n",
    "\n",
    "@jit\n",
    "def _jax_compute_size_two_entropies(x):\n",
    "    return -jnp.log(jnp.einsum('tilm,siml,tjrk,sjkr->ij', x, x, x, x))\n",
    "\n",
    "def compute_entropies_from_shadow(shadow):\n",
    "    \"\"\"\n",
    "    compute second-order Rényi entanglement entropies for all subsystems of size at most two, using the classical shadow\n",
    "    protocol\n",
    "    \"\"\"\n",
    "    local_snapshots = shadow.local_snapshots()\n",
    "    shadow_size = shadow.snapshots\n",
    "\n",
    "    # compute size two entropies\n",
    "    entropies = np.array(_jax_compute_size_two_entropies(local_snapshots) + 2 * np.log(shadow_size))\n",
    "\n",
    "    # compute size one entropies\n",
    "    entropies_size_one = np.array(_jax_compute_size_one_entropies(local_snapshots) + 2 * np.log(shadow_size))\n",
    "    np.fill_diagonal(entropies, entropies_size_one)\n",
    "\n",
    "    return entropies.real\n",
    "\n",
    "def compute_correlation_matrix_from_shadow(shadow):\n",
    "    wires = shadow.bits.shape[1]\n",
    "\n",
    "    qubit_pairs = list(it.combinations(range(wires), r=2))\n",
    "\n",
    "    correlations = np.zeros((wires, wires))\n",
    "    np.fill_diagonal(correlations, 1.0)\n",
    "\n",
    "    for idx, (i, j) in enumerate(qubit_pairs):\n",
    "        obs = qml.PauliX(i) @ qml.PauliX(j) + qml.PauliY(i) @ qml.PauliY(j) + qml.PauliZ(i) @ qml.PauliZ(j)\n",
    "        correlations[i, j] = correlations[j, i] = shadow.expval(H=obs, k=1) / 3\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 22844.79it/s]\n"
     ]
    }
   ],
   "source": [
    "shots = 20000\n",
    "_samples = samples[:, :shots, :]\n",
    "model_recipes_list = _samples // 2\n",
    "model_bits_list = _samples - 2 * model_recipes_list\n",
    "\n",
    "shadow_list = []\n",
    "for i in tqdm(range(len(model_recipes_list))):\n",
    "    shadow_list.append(qml.ClassicalShadow(bits=model_bits_list[i], recipes=model_recipes_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_correlation_matrix_list = [compute_correlation_matrix_from_shadow(shadow=shadow_list[i]) for i in tqdm(range(len(shadow_list)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2528625408222367"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_error = []\n",
    "for i in range(len(predicted_correlation_matrix_list)):\n",
    "    correlation_error.append((predicted_correlation_matrix_list[i] - exact_correlation_matrix_list[i])**2)\n",
    "correlation_error = np.array(correlation_error)\n",
    "correlation_error = np.mean(correlation_error)\n",
    "correlation_error = np.sqrt(correlation_error)\n",
    "correlation_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('gqs': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "b048696420ae3fce02275cea853b132b130a64627dc059cc7f94d62d83254479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
